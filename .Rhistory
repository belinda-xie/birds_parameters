tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp5_test.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp5_test-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp5_test.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp5_test-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp5_test.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp5_test-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp6.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp6-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp5.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp5-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
rstudioapi::terminalCreate()
# -- user should edit --
rawfile <-  "C:/Users/belin/Documents/urns_exp6_top-up.csv"
tidyfile <- "C:/Users/belin/Documents/urns_exp6_top-up-tidied.csv"
# -- parse the raw data into something nicer --
makenice <- TRUE
if(makenice) {
# raw data
raw <- read.csv(file=rawfile, header=TRUE, stringsAsFactors=FALSE)
# create tidy from 1st subject
nsubj <- dim(raw)[1]
tidy <- read.csv(text=raw[1,1])
tidy$subj_id <- 1
tidy$timestamp <- raw[1,2]
if(is.null(tidy$gender)) tidy$gender <- NA
# if there are multiple subjects, iterate
if(nsubj>1) {
for( i in 2:nsubj) {
tmp <- read.csv(text=raw[i,1])
tmp$subj_id <- i
tmp$timestamp <- raw[i,2]
if(is.null(tmp$gender)) tmp$gender <- NA
tidy <- rbind(tidy, tmp)
}
}
# reorder columns because I'm like that
leftvars <- c("subj_id", "timestamp", "gender",
"age", "language", "country", "turkcode")
rightvars <- setdiff(names(tidy), leftvars)
tidy <- tidy[, c(leftvars, rightvars)]
# save
write.csv(tidy, file=tidyfile, row.names = FALSE)
}
devtools::install_github('yihui/tinytex')
install.packages('tinytex')
tinytex::install_tinytex()
update.packages(ask = FALSE, checkBuilt = TRUE)
tinytex::tlmgr_update()  # update LaTeX packages
install.packages("rmarkdown")
install.packages("rmarkdown")
install.packages("rmarkdwon")
install.packages("rmarkdown")
install.packages('knitr')
install.packages("stringi")
install.packages("stringi", dependencies=TRUE, INSTALL_opts = c('--no-lock'))
install.packages("stringr", dependencies=TRUE, INSTALL_opts = c('--no-lock'))
install.packages("tidyr")
install.packages("tidyr")
install.packages("installr")
# ------------------------------------------------------------------------- #
# --------- Adding types, but not tokens, affects property induction ------ #
# ----------------- Modeling Experiment 3 conditions ---------------------- #
# -------------------------------------------------------------------------- #
require(cowplot)
require(tidyverse)
require(BayesFactor)
require(ggpubr)
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
source("./BayesGen-BX.R")
set.seed(1)
# ------------ PARAMETERS ----------------------------- #
phi <- 1                 # phi = 1: uniform prior over hypotheses, phi > 1: greater prior belief in larger hypotheses
nits <- 1000             # number of iterations
# --------------------------- generate predictions ------------------------------ #
parits <- 3000  # how many times do I want to test out different parameter values?
test <- c(.49, .7, .9)  # this is overridden in l. 50
nt <- length(test)      # number of test items
namescol <- c("typelabel", "tokenlabel")
decreaseHigh <- matrix(data = c(rep(0, parits*2)), nrow = parits)
colnames(decreaseHigh) <- namescol
decreaseLow <- decreaseMed <- decreaseHigh
pars <- c("thetaType", "thetaToken", "target1", "target2", "target3", "target4", "target5", "target6", "typesd", "tokensd")
parValues <- matrix(data = c(rep(0, parits*length(pars))), nrow = parits)
colnames(parValues) <- pars
# --------------------------- generate predictions ------------------------------ #
# use a loop to test different parameter values
for (a in 1:parits) {
# sample different parameter values
# theta values to represent sampling assumptions/informational value
thetaType <- runif(1, min = .1, max = .5)          # value used to discuss modeling results = .3
thetaToken <- runif(1, min = .1, max = thetaType)  # value in paper = .15
# stimulus values for types
targetsM <- runif(1, .2, .6) # select the centre of a uniform distribution, from which to sample types
targetsW <- runif(1, .005, .2)  # select the width of a uniform distribution, from which to sample types
targets <- runif(6, targetsM - targetsW, targetsM + targetsW) # sample from that uniform distribution
targets <- sort(targets)
target1 <- targets[4]  # value in paper = .452
target2 <- targets[3]                   # .45
target3 <- targets[1]                   # .446
target4 <- targets[2]                   # .448
target5 <- targets[5]                   # .454
target6 <- targets[6]                   # .456
# when randomly generating stimulus values for types/tokens, how much standard deviation to use?
typesd <- runif(1, .01, .05)            # .03
tokensd <- typesd/3                     # .01, > experiment 1 (.009) because images are now reflected/rotated
bg1token <- matrix(data = c(rep(0, nits*nt)),   # create enough 0s for each iteration x each test item - to be filled with predicted generalisation probability
nrow = nt)                   # 1 row for each test item (high, medium, low sim)
bg2token <- bg3token <- bg4token <- bg5token <- bg1token # make all others in the same way - need one matrix per condition
bg1type <- bg2type <- bg3type <- bg4type <- bg5type <- bg1token
for( i in 1:nits ) {     # average out predictions over nits iterations
train1 <- rnorm(1, mean = target1, sd = typesd) # generates number randomly from a uniform distribution, then /.2 makes it smallish, then +.4 to approach .5
# generalisation from adding OLD tokens
train1a <- rnorm(1, mean = train1, sd = tokensd)  # the repetition is constrained to be within a range around the first training item
train1b <- rnorm(1, mean = train1, sd = tokensd)  # the above is true for all tokens
train1c <- rnorm(1, mean = train1, sd = tokensd)
train1d <- rnorm(1, mean = train1, sd = tokensd)
train1e <- rnorm(1, mean = train1, sd = tokensd)
# testH <- (max(c(train1, train1a, train1b, train1c, train1d, train1e)) + .01)
# test <- c(testH, testH+((.9-testH)/2), .9)
test <- c(.51, .707, .9)
bg1token[,i] <- (BayesGen(train1, test, thetaType, phi))*1/2 +
(BayesGen(c(train1a), test, thetaToken, phi))*1/2
bg2token[,i] <- (BayesGen(train1, test, thetaType, phi))*1/3 +
(BayesGen(c(train1a, train1b), test, thetaToken, phi))*2/3
bg3token[,i] <- (BayesGen(train1, test, thetaType, phi))*1/4 +
(BayesGen(c(train1a, train1b, train1c), test, thetaToken, phi))*3/4
bg4token[,i] <- (BayesGen(train1, test, thetaType, phi))*1/5 +
(BayesGen(c(train1a, train1b, train1c, train1d), test, thetaToken, phi))*4/5
bg5token[,i] <- (BayesGen(train1, test, thetaType, phi))*1/6 +
(BayesGen(c(train1a, train1b, train1c, train1d, train1e), test, thetaToken, phi))*5/6
# generalisation from adding NEW tokens
train1v <- rnorm(1, mean = target2, sd = typesd)  # the repetition is constrained to be within a range around the first training item
train1w <- rnorm(1, mean = target3, sd = typesd)  # the above is true for all tokens
train1x <- rnorm(1, mean = target4, sd = typesd)
train1y <- rnorm(1, mean = target5, sd = typesd)
train1z <- rnorm(1, mean = target6, sd = typesd)
testHnew <- (max(c(train1, train1v, train1w, train1x, train1y, train1z)) + .01)
testnew <- c(testHnew, testHnew+((.9-testHnew)/2), .9)
# adding type-label isntances
bg1type[,i] <- BayesGen(c(train1, train1v), test, thetaType, phi)
bg2type[,i] <- BayesGen(c(train1, train1v, train1w), test, thetaType, phi)
bg3type[,i] <- BayesGen(c(train1, train1v, train1w, train1x), test, thetaType, phi)
bg4type[,i] <- BayesGen(c(train1, train1v, train1w, train1x, train1y), test, thetaType, phi)
bg5type[,i] <- BayesGen(c(train1, train1v, train1w, train1x, train1y, train1z), test, thetaType, phi)
}
bg1token <- rowMeans(bg1token)          # calculate the mean of the N(nits) generalisation probabilities for each similarity category
bg2token <- rowMeans(bg2token)
bg3token <- rowMeans(bg3token)
bg4token <- rowMeans(bg4token)
bg5token <- rowMeans(bg5token)
bg1type <- rowMeans(bg1type)          # calculate the mean of the N(nits) generalisation probabilities for each similarity category
bg2type <- rowMeans(bg2type)
bg3type <- rowMeans(bg3type)
bg4type <- rowMeans(bg4type)
bg5type <- rowMeans(bg5type)
decreaseHigh[a,1] <- bg1type[1] > bg5type[1]
decreaseHigh[a,2] <- bg1token[1] > bg5token[1]
decreaseMed[a,1] <- bg1type[2] > bg5type[2]
decreaseMed[a,2] <- bg1token[2] > bg5token[2]
decreaseLow[a,1] <- bg1type[3] > bg5type[3]
decreaseLow[a,2] <- bg1token[3] > bg5token[3]
parValues[a,] <- c(thetaType, thetaToken, target1, target2, target3, target4, target5, target6, typesd, tokensd)
}
sum(decreaseHigh[,1]) # adding type-label instances increases gen at high-sim category
decreaseHigh1 <- cbind(decreaseHigh[,1], parValues)
head(decreaseHigh1)
colnames(decreaseHigh1)[1] <- "decreased"
head(decreaseHigh1)
write.csv(decreaseHigh1, "./decreaseHigh1.csv")
decreaseHigh1 <- as.data.frame(decreaseHigh1)
decreaseHigh1 <- pivot_longer(decreaseHigh1, thetaType:tokensd, names_to = "parameter", values_to = "value")
ggplot(typesMed3Long, aes(x=value)) +
geom_histogram() +
facet_wrap(~ decreased + parameter, scales = "free_x")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
facet_wrap(~ decreased + parameter, scales = "free_x")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(aes(xintercept=mean(value)),
color="blue", linetype="dashed", size=1)
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(aes(xintercept=mean(value)),
color="blue", linetype="dashed", size=1) +
facet_wrap(~ decreased + parameter, scales = "free_x")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"),
linetype="dashed") +
facet_wrap(~ decreased + parameter, scales = "free_x")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=decreaseHigh1, aes(xintercept=grp.mean, color="red"),
linetype="dashed") +
facet_wrap(~ decreased + parameter, scales = "free_x")
mu <- ddply(decreaseHigh1, "decreased", summarise, grp.mean=mean(value))
library(plyr)
library(plyr)
mu <- ddply(decreaseHigh1, "decreased", summarise, grp.mean=mean(value))
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"),
linetype="dashed") +
facet_wrap(~ decreased + parameter, scales = "free_x")
?facet_wrap
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"),
linetype="dashed") +
facet_wrap(~ decreased + parameter, scales = "free")
mu
?ddply
mu <- ddply(decreaseHigh1, c("decreased", "parameter"), summarise, grp.mean=mean(value))
mu
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"),
linetype="dashed") +
facet_wrap(~ decreased + parameter, scales = "free")
mu <- ddply(decreaseHigh1, c("decreased", "parameter"), summarise, grp.mean=mean(value), grp.mode=mode(value))
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free")
mu
?summarise
mode(decreaseHigh1$value)
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
Mode(decreaseHigh1$value)
mu <- ddply(decreaseHigh1, c("decreased", "parameter"), summarise, grp.mean=mean(value), grp.mode=Mode(value))
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
# geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free")
head(decreaseHigh1)
decreaseHigh1$decreased <- as.character(as.numeric(decreaseHigh1$decreased))
head(decreaseHigh1)
decreaseHigh1$decreased <- gsub("0", "Did not reproduce", decreaseHigh1$decreased)
library(plyr)
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mu <- ddply(decreaseHigh1, c("decreased", "parameter"), summarise, grp.mean=mean(value), grp.mode=Mode(value))
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw()
decreaseHigh1$decreased <- gsub("0", "Reproduced", decreaseHigh1$decreased)
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw(legend.position = "none")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram() +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram(bins = 20) +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
decreaseHigh1$decreased <- gsub("1", "Reproduced", decreaseHigh1$decreased)
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram(bins = 20) +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
decreaseHigh1 <- read.csv("./decreaseHigh1.csv")
decreaseHigh1 <- as.data.frame(decreaseHigh1)
decreaseHigh1 <- pivot_longer(decreaseHigh1, thetaType:tokensd, names_to = "parameter", values_to = "value")
decreaseHigh1$decreased <- as.character(as.numeric(decreaseHigh1$decreased))
decreaseHigh1$decreased <- gsub("0", "Did not reproduce", decreaseHigh1$decreased)
decreaseHigh1$decreased <- gsub("1", "Reproduced", decreaseHigh1$decreased)
library(plyr)
Mode <- function(x) {
ux <- unique(x)
ux[which.max(tabulate(match(x, ux)))]
}
mu <- ddply(decreaseHigh1, c("decreased", "parameter"), summarise, grp.mean=mean(value), grp.mode=Mode(value))
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram(bins = 20) +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items", x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
ggplot(decreaseHigh1, aes(x=value)) +
geom_histogram(bins = 20) +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(
# title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items",
x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
rm(list = ls())
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))
typesMed3 <- read.csv("./typesMed3.csv")
typesMed3 <- as.data.frame(typesMed3)
typesMed3Long <- pivot_longer(typesMed3, thetaType:tokensd, names_to = "parameter", values_to = "value")
typesMed3 <- read.csv("./typesMed3.csv")
typesMed3 <- as.data.frame(typesMed3)
typesMed3 <- pivot_longer(typesMed3, thetaType:tokensd, names_to = "parameter", values_to = "value")
typesMed3$decreased <- as.character(as.numeric(typesMed3$decreased))
typesMed3$decreased <- gsub("0", "Did not reproduce", typesMed3$decreased)
typesMed3$decreased <- gsub("1", "Reproduced", typesMed3$decreased)
mu <- ddply(typesMed3, c("decreased", "parameter"), summarise, grp.mean=mean(value))
ggplot(typesMed3, aes(x=value)) +
geom_histogram(bins = 20) +
geom_vline(data=mu, aes(xintercept=grp.mean, color="red"), linetype="dashed") +
labs(
# title = "Experiment 3: Adding type-label instances decreases gen for high-similarity items",
x = "Parameter value", y = "Count") +
# geom_vline(data=mu, aes(xintercept=grp.mode, color="blue"), linetype="dotted") +
facet_wrap(~ decreased + parameter, scales = "free") +
theme_bw() +
theme(legend.position = "none")
